{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import gutenberg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '<s>'\n",
    "STOP = '</s>'\n",
    "UNK = '<unk>'\n",
    "l1 = 0.6\n",
    "l2 = 0.2\n",
    "l3 = 0.2\n",
    "punc = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_Train_data(data):\n",
    "    for line in data :\n",
    "        line.insert(0,START)\n",
    "        line.insert(0,START)\n",
    "        line.append(STOP)\n",
    "    words = list(itertools.chain.from_iterable(data))\n",
    "    data_words = [x.lower() for x in words]\n",
    "    data_words.append(UNK)\n",
    "    freq = nltk.FreqDist(data_words)\n",
    "    unknown = list()\n",
    "    for word in freq.keys():\n",
    "        if freq[word] == 1:\n",
    "            unknown.append(word)\n",
    "    unknown = set(unknown)\n",
    "    vocab = list()\n",
    "    for w in data_words :\n",
    "        if w in unknown :\n",
    "            vocab.append(UNK)\n",
    "        else :\n",
    "            vocab.append(w)\n",
    "    data_words = vocab\n",
    "    return data , words, data_words ,unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram_table( data_words ):\n",
    "    cfreq_2gram = nltk.ConditionalFreqDist(nltk.bigrams(data_words))\n",
    "    cprob_2gram = nltk.ConditionalProbDist(cfreq_2gram, nltk.MLEProbDist)\n",
    "    return cfreq_2gram,cprob_2gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram_table( data_words ):\n",
    "    trigrams = nltk.trigrams(data_words)\n",
    "    sen = list()\n",
    "    sen = [((a,b),c) for (a,b,c) in trigrams]\n",
    "    cfreq_3gram = nltk.ConditionalFreqDist(sen)\n",
    "    cprob_3gram = nltk.ConditionalProbDist(cfreq_3gram, nltk.MLEProbDist)\n",
    "    return cfreq_3gram,cprob_3gram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_prob ( word, freq_1gram,len_):\n",
    "    return freq_1gram[ word] / float(len_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz ( w1 , w2 , w3 , cprob_3gram , cprob_2gram ,freq_1gram,len_):\n",
    "        if cprob_3gram[(w1,w2)].prob(w3) > 0:\n",
    "            #print 3 \n",
    "            return cprob_3gram[(w1,w2)].prob(w3)\n",
    "        else:\n",
    "            if cprob_2gram[w2].prob(w3) > 0:\n",
    "                #print 2\n",
    "                return cprob_2gram[w2].prob(w3)\n",
    "            else :\n",
    "                #print 1\n",
    "                return unigram_prob(w3,freq_1gram,len_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate( w1 , w2 , w3 , cprob_3gram , cprob_2gram ,data_words):\n",
    "    x = cprob_3gram[(w1,w2)].prob(w3)\n",
    "    y = cprob_2gram[w2].prob(w3)\n",
    "    z = unigram_prob(w3 ,data_words)\n",
    "    return l1*x + l2*y + l3*z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(Test,vocab_set):\n",
    "    test = []\n",
    "    for line in Test :\n",
    "        t = []\n",
    "        for word in line :\n",
    "            if word not in vocab_set :\n",
    "                t.append(UNK)\n",
    "            else :\n",
    "                t.append(word)\n",
    "        #t = [i.lower() for i in line if i not in punc]\n",
    "        t.append(STOP)\n",
    "        t.insert(0,START)\n",
    "        t.insert(0,START)\n",
    "        test.append(t)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_perplexity(test,cprob_3gram,cprob_2gram,freq_1gram,len_):\n",
    "    perp = 0\n",
    "    n = 0\n",
    "    for line in test :\n",
    "        for i in range(2,len(line)):\n",
    "            val = katz(line[i-2],line[i-1],line[i],cprob_3gram,cprob_2gram,freq_1gram,len_)\n",
    "            #val = interpolate(line[i-2],line[i-1],line[i],cprob_3gram,cprob_2gram,data_words)\n",
    "            perp += math.log(val,2)\n",
    "        n += len(line)\n",
    "    perp = (-1) * (perp / float(n))\n",
    "    return  2**perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(Train , Test):\n",
    "    Train, words, Train_words, unknown = preprocess_Train_data ( Train)\n",
    "    print \"step1\"\n",
    "    vocab_set = set( Train_words)\n",
    "    print \"step2\"\n",
    "    freq_1gram = nltk.FreqDist(Train_words)\n",
    "    len_ = len(Train_words)\n",
    "    print \"step3\"\n",
    "    cfreq_2gram, cprob_2gram = create_bigram_table ( Train_words)\n",
    "    print \"step3\"\n",
    "    cfreq_3gram, cprob_3gram = create_trigram_table ( Train_words)\n",
    "    print \"step4\"\n",
    "    test = preprocess_test ( Test,vocab_set)\n",
    "    print \"step5\"\n",
    "    return cprob_3gram,cprob_2gram,freq_1gram,len_,test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_dataset(dataset):\n",
    "    if dataset == \"brown\":\n",
    "        brown_sent = brown.sents()\n",
    "        D1_Train,D1_Test = train_test_split(brown_sent,train_size = 0.8 , random_state = 7)    \n",
    "        return create_model(D1_Train,D1_Test)\n",
    "\n",
    "    else :\n",
    "        if dataset == \"gutenberg\":\n",
    "            gut_sent = gutenberg.sents()\n",
    "            D2_Train,D2_Test = train_test_split(gut_sent,train_size = 0.8 , random_state = 7)\n",
    "            return create_model(D2_Train,D2_Test)\n",
    "        else :\n",
    "            brown_sent = brown.sents()\n",
    "            gut_sent = gutenberg.sents()\n",
    "            sent = brown_sent + gut_sent\n",
    "            D3_Train,D3_Test = train_test_split(sent,train_size = 0.8 , random_state = 7)\n",
    "            return create_model(D3_Train,D3_Test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on Brown dataset\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step3\n",
      "step4\n",
      "step5\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity on Brown dataset\")\n",
    "bcprob_3gram,bcprob_2gram,bfreq_1gram,blen_,btest = try_dataset(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.191050418\n"
     ]
    }
   ],
   "source": [
    "perplexity = evaluate_perplexity (btest ,bcprob_3gram, bcprob_2gram, bfreq_1gram,blen_)\n",
    "print perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on Gutenberg dataset\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step3\n",
      "step4\n",
      "step5\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity on Gutenberg dataset\")\n",
    "gcprob_3gram,gcprob_2gram,gfreq_1gram,glen_,gtest = try_dataset(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.2924523313\n"
     ]
    }
   ],
   "source": [
    "perplexity = evaluate_perplexity (gtest ,gcprob_3gram, gcprob_2gram, gfreq_1gram,glen_)\n",
    "print perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on Brown+Gutenberg dataset\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step3\n",
      "step4\n",
      "step5\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity on Brown+Gutenberg dataset\")\n",
    "mcprob_3gram,mcprob_2gram,mfreq_1gram,mlen_,mtest = try_dataset(\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.3793147537\n"
     ]
    }
   ],
   "source": [
    "perplexity = evaluate_perplexity (mtest ,mcprob_3gram, mcprob_2gram, mfreq_1gram,mlen_)\n",
    "print perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
